{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entrenamiento y Evaluaci√≥n de Modelos de Regresi√≥n\n",
    "Este notebook contiene el entrenamiento y evaluaci√≥n de modelos de machine learning para regresi√≥n.\n",
    "\n",
    "## Modelos a evaluar:\n",
    "1. **Regresi√≥n Log√≠stica Multivariable** (LinearRegression)\n",
    "2. **Support Vector Regression (SVR)**\n",
    "3. **XGBoost Regressor**\n",
    "\n",
    "## Objetivos:\n",
    "- Entrenar modelos con diferentes hiperpar√°metros\n",
    "- Evaluar rendimiento con m√©tricas de regresi√≥n\n",
    "- Analizar importancia de caracter√≠sticas\n",
    "- Comparar modelos y seleccionar el mejor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, validation_curve\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_absolute_percentage_error\n",
    "from sklearn.inspection import permutation_importance\n",
    "import xgboost as xgb\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Librer√≠as importadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carga y Preparaci√≥n de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Cargar el dataset\n# NOTA: Reemplaza 'tu_dataset.csv' con la ruta real de tu archivo\nfile_path = 'tu_dataset.csv'\n\ntry:\n    df = pd.read_csv(file_path)\n    print(f\"Dataset cargado exitosamente: {df.shape[0]} filas y {df.shape[1]} columnas\")\nexcept FileNotFoundError:\n    print(\"Archivo no encontrado. Utilizando dataset de ejemplo.\")\n    # Crear dataset de ejemplo para demostraci√≥n con 10 caracter√≠sticas\n    np.random.seed(42)\n    n_samples = 1000\n    df = pd.DataFrame({\n        'feature_1': np.random.normal(50, 15, n_samples),\n        'feature_2': np.random.exponential(2, n_samples),\n        'feature_3': np.random.uniform(0, 100, n_samples),\n        'feature_4': np.random.gamma(2, 2, n_samples),\n        'feature_5': np.random.beta(2, 5, n_samples) * 100,\n        'feature_6': np.random.lognormal(1, 0.5, n_samples),\n        'feature_7': np.random.weibull(1.5, n_samples) * 50,\n        'feature_8': np.random.poisson(5, n_samples),\n        'feature_9': np.random.triangular(0, 50, 100, n_samples),\n        'feature_10': np.random.pareto(3, n_samples) * 10,\n        'target': np.random.normal(75, 20, n_samples)\n    })\n    # Agregar correlaci√≥n artificial con m√∫ltiples caracter√≠sticas\n    df['target'] = (0.25 * df['feature_1'] + 0.15 * df['feature_3'] + 0.1 * df['feature_4'] + \n                   0.08 * df['feature_6'] + 0.12 * df['feature_7'] + 0.05 * df['feature_9'] + \n                   np.random.normal(0, 10, n_samples))\n    print(f\"Dataset de ejemplo creado: {df.shape[0]} filas y {df.shape[1]} columnas\")\n\n# Verificar si existe la columna target\nif 'target' not in df.columns:\n    print(\"‚ö†Ô∏è ADVERTENCIA: No se encontr√≥ la columna 'target'. Por favor, especifica cu√°l es tu variable objetivo.\")\n    print(f\"Columnas disponibles: {list(df.columns)}\")\nelse:\n    print(f\"‚úÖ Variable objetivo 'target' encontrada\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparaci√≥n de datos\n",
    "# Separar caracter√≠sticas y variable objetivo\n",
    "feature_cols = [col for col in df.columns if col != 'target']\n",
    "X = df[feature_cols]\n",
    "y = df['target']\n",
    "\n",
    "print(f\"Caracter√≠sticas seleccionadas: {feature_cols}\")\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")\n",
    "\n",
    "# Verificar valores faltantes\n",
    "missing_X = X.isnull().sum().sum()\n",
    "missing_y = y.isnull().sum()\n",
    "print(f\"\\nValores faltantes en X: {missing_X}\")\n",
    "print(f\"Valores faltantes en y: {missing_y}\")\n",
    "\n",
    "# Remover filas con valores faltantes si existen\n",
    "if missing_X > 0 or missing_y > 0:\n",
    "    mask = ~(X.isnull().any(axis=1) | y.isnull())\n",
    "    X = X[mask]\n",
    "    y = y[mask]\n",
    "    print(f\"Despu√©s de limpiar datos: X={X.shape}, y={y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi√≥n train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=None\n",
    ")\n",
    "\n",
    "print(f\"Conjunto de entrenamiento: {X_train.shape[0]} muestras\")\n",
    "print(f\"Conjunto de prueba: {X_test.shape[0]} muestras\")\n",
    "print(f\"Proporci√≥n train/test: {X_train.shape[0]/X_test.shape[0]:.1f}\")\n",
    "\n",
    "# Estad√≠sticas de la variable objetivo\n",
    "print(f\"\\nEstad√≠sticas de la variable objetivo:\")\n",
    "print(f\"Train - Media: {y_train.mean():.2f}, Std: {y_train.std():.2f}\")\n",
    "print(f\"Test  - Media: {y_test.mean():.2f}, Std: {y_test.std():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Escalado de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar diferentes scalers\n",
    "scalers = {\n",
    "    'StandardScaler': StandardScaler(),\n",
    "    'RobustScaler': RobustScaler(),\n",
    "    'NoScaler': None\n",
    "}\n",
    "\n",
    "# Funci√≥n para aplicar escalado\n",
    "def apply_scaling(scaler, X_train, X_test):\n",
    "    if scaler is None:\n",
    "        return X_train, X_test\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled\n",
    "\n",
    "print(\"Escaladores preparados:\")\n",
    "for name in scalers.keys():\n",
    "    print(f\"  ‚Ä¢ {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Definici√≥n de M√©tricas de Evaluaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metrics(y_true, y_pred):\n",
    "    \"\"\"Calcula m√∫ltiples m√©tricas de regresi√≥n\"\"\"\n",
    "    metrics = {\n",
    "        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),\n",
    "        'MAE': mean_absolute_error(y_true, y_pred),\n",
    "        'R¬≤': r2_score(y_true, y_pred),\n",
    "        'MAPE': mean_absolute_percentage_error(y_true, y_pred) * 100,\n",
    "        'Adjusted_R¬≤': 1 - (1 - r2_score(y_true, y_pred)) * (len(y_true) - 1) / (len(y_true) - X_train.shape[1] - 1)\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def print_metrics(metrics, title=\"M√©tricas\"):\n",
    "    \"\"\"Imprime m√©tricas de forma organizada\"\"\"\n",
    "    print(f\"\\n=== {title} ===\")\n",
    "    for metric, value in metrics.items():\n",
    "        if metric in ['R¬≤', 'Adjusted_R¬≤']:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "        elif metric == 'MAPE':\n",
    "            print(f\"{metric}: {value:.2f}%\")\n",
    "        else:\n",
    "            print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"Funciones de m√©tricas definidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelo 1: Regresi√≥n Lineal con Regularizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç ENTRENANDO MODELOS DE REGRESI√ìN LINEAL\")\n",
    "\n",
    "# Modelos de regresi√≥n lineal a probar\n",
    "linear_models = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(max_iter=2000),\n",
    "    'ElasticNet': ElasticNet(max_iter=2000)\n",
    "}\n",
    "\n",
    "# Hiperpar√°metros para b√∫squeda\n",
    "linear_params = {\n",
    "    'Ridge': {'alpha': [0.1, 1, 10, 100, 1000]},\n",
    "    'Lasso': {'alpha': [0.001, 0.01, 0.1, 1, 10]},\n",
    "    'ElasticNet': {\n",
    "        'alpha': [0.001, 0.01, 0.1, 1],\n",
    "        'l1_ratio': [0.1, 0.3, 0.5, 0.7, 0.9]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Resultados de modelos lineales\n",
    "linear_results = {}\n",
    "\n",
    "# Usar StandardScaler para modelos lineales\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled, X_test_scaled = apply_scaling(scaler, X_train, X_test)\n",
    "\n",
    "for model_name, model in linear_models.items():\n",
    "    print(f\"\\nüîß Entrenando {model_name}...\")\n",
    "    \n",
    "    if model_name in linear_params:\n",
    "        # B√∫squeda de hiperpar√°metros con validaci√≥n cruzada\n",
    "        grid_search = GridSearchCV(\n",
    "            model, linear_params[model_name], \n",
    "            cv=5, scoring='neg_mean_squared_error', \n",
    "            n_jobs=-1\n",
    "        )\n",
    "        grid_search.fit(X_train_scaled, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "        print(f\"  Mejores hiperpar√°metros: {grid_search.best_params_}\")\n",
    "    else:\n",
    "        # Modelo sin hiperpar√°metros\n",
    "        best_model = model\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = best_model.predict(X_train_scaled)\n",
    "    y_test_pred = best_model.predict(X_test_scaled)\n",
    "    \n",
    "    # M√©tricas\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    \n",
    "    # Validaci√≥n cruzada\n",
    "    cv_scores = cross_val_score(best_model, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    linear_results[model_name] = {\n",
    "        'model': best_model,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_rmse_std': cv_rmse_std,\n",
    "        'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "    }\n",
    "    \n",
    "    print_metrics(train_metrics, \"Entrenamiento\")\n",
    "    print_metrics(test_metrics, \"Prueba\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelos lineales entrenados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelo 2: Support Vector Regression (SVR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç ENTRENANDO SUPPORT VECTOR REGRESSION\")\n",
    "\n",
    "# Hiperpar√°metros para SVR\n",
    "svr_params = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "    'epsilon': [0.01, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Diferentes kernels a probar\n",
    "svr_kernels = ['linear', 'rbf', 'poly']\n",
    "svr_results = {}\n",
    "\n",
    "# Usar RobustScaler para SVR (m√°s robusto a outliers)\n",
    "robust_scaler = RobustScaler()\n",
    "X_train_robust, X_test_robust = apply_scaling(robust_scaler, X_train, X_test)\n",
    "\n",
    "for kernel in svr_kernels:\n",
    "    print(f\"\\nüîß Entrenando SVR con kernel {kernel}...\")\n",
    "    \n",
    "    # Crear modelo SVR\n",
    "    svr_model = SVR(kernel=kernel)\n",
    "    \n",
    "    # Ajustar par√°metros seg√∫n el kernel\n",
    "    current_params = svr_params.copy()\n",
    "    if kernel == 'linear':\n",
    "        current_params.pop('gamma')  # Gamma no es relevante para kernel lineal\n",
    "    elif kernel == 'poly':\n",
    "        current_params['degree'] = [2, 3, 4]  # Agregar grado para polynomial\n",
    "    \n",
    "    # B√∫squeda de hiperpar√°metros\n",
    "    grid_search = GridSearchCV(\n",
    "        svr_model, current_params, \n",
    "        cv=5, scoring='neg_mean_squared_error', \n",
    "        n_jobs=-1, verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search.fit(X_train_robust, y_train)\n",
    "    best_svr = grid_search.best_estimator_\n",
    "    \n",
    "    print(f\"  Mejores hiperpar√°metros: {grid_search.best_params_}\")\n",
    "    \n",
    "    # Predicciones\n",
    "    y_train_pred = best_svr.predict(X_train_robust)\n",
    "    y_test_pred = best_svr.predict(X_test_robust)\n",
    "    \n",
    "    # M√©tricas\n",
    "    train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "    test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "    \n",
    "    # Validaci√≥n cruzada\n",
    "    cv_scores = cross_val_score(best_svr, X_train_robust, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "    cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "    cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "    \n",
    "    svr_results[f'SVR_{kernel}'] = {\n",
    "        'model': best_svr,\n",
    "        'train_metrics': train_metrics,\n",
    "        'test_metrics': test_metrics,\n",
    "        'cv_rmse': cv_rmse,\n",
    "        'cv_rmse_std': cv_rmse_std,\n",
    "        'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "    }\n",
    "    \n",
    "    print_metrics(train_metrics, \"Entrenamiento\")\n",
    "    print_metrics(test_metrics, \"Prueba\")\n",
    "    print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelos SVR entrenados correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Modelo 3: XGBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç ENTRENANDO XGBOOST REGRESSOR\")\n",
    "\n",
    "# Hiperpar√°metros para XGBoost\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 4, 5, 6],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Crear modelo XGBoost\n",
    "xgb_model = xgb.XGBRegressor(\n",
    "    random_state=42,\n",
    "    verbosity=0,\n",
    "    eval_metric='rmse'\n",
    ")\n",
    "\n",
    "# XGBoost no requiere escalado, usar datos originales\n",
    "print(\"üîß Entrenando XGBoost (puede tardar varios minutos)...\")\n",
    "\n",
    "# B√∫squeda aleatoria para reducir tiempo de c√≥mputo\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Usar RandomizedSearchCV en lugar de GridSearchCV para mayor eficiencia\n",
    "random_search = RandomizedSearchCV(\n",
    "    xgb_model, xgb_params,\n",
    "    n_iter=50,  # N√∫mero de combinaciones a probar\n",
    "    cv=5, scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1, random_state=42,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "random_search.fit(X_train, y_train)\n",
    "best_xgb = random_search.best_estimator_\n",
    "\n",
    "print(f\"  Mejores hiperpar√°metros: {random_search.best_params_}\")\n",
    "\n",
    "# Predicciones\n",
    "y_train_pred = best_xgb.predict(X_train)\n",
    "y_test_pred = best_xgb.predict(X_test)\n",
    "\n",
    "# M√©tricas\n",
    "train_metrics = calculate_metrics(y_train, y_train_pred)\n",
    "test_metrics = calculate_metrics(y_test, y_test_pred)\n",
    "\n",
    "# Validaci√≥n cruzada\n",
    "cv_scores = cross_val_score(best_xgb, X_train, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "cv_rmse = np.sqrt(-cv_scores.mean())\n",
    "cv_rmse_std = np.sqrt(cv_scores.std())\n",
    "\n",
    "xgb_results = {\n",
    "    'model': best_xgb,\n",
    "    'train_metrics': train_metrics,\n",
    "    'test_metrics': test_metrics,\n",
    "    'cv_rmse': cv_rmse,\n",
    "    'cv_rmse_std': cv_rmse_std,\n",
    "    'predictions': {'train': y_train_pred, 'test': y_test_pred}\n",
    "}\n",
    "\n",
    "print_metrics(train_metrics, \"Entrenamiento\")\n",
    "print_metrics(test_metrics, \"Prueba\")\n",
    "print(f\"CV RMSE: {cv_rmse:.4f} (¬±{cv_rmse_std:.4f})\")\n",
    "\n",
    "print(\"\\n‚úÖ Modelo XGBoost entrenado correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Comparaci√≥n de Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar todos los resultados\n",
    "all_results = {**linear_results, **svr_results, 'XGBoost': xgb_results}\n",
    "\n",
    "# Crear DataFrame de comparaci√≥n\n",
    "comparison_data = []\n",
    "for model_name, results in all_results.items():\n",
    "    comparison_data.append({\n",
    "        'Modelo': model_name,\n",
    "        'Train_RMSE': results['train_metrics']['RMSE'],\n",
    "        'Test_RMSE': results['test_metrics']['RMSE'],\n",
    "        'Train_R¬≤': results['train_metrics']['R¬≤'],\n",
    "        'Test_R¬≤': results['test_metrics']['R¬≤'],\n",
    "        'Train_MAE': results['train_metrics']['MAE'],\n",
    "        'Test_MAE': results['test_metrics']['MAE'],\n",
    "        'CV_RMSE': results['cv_rmse'],\n",
    "        'CV_RMSE_Std': results['cv_rmse_std'],\n",
    "        'Overfitting': results['train_metrics']['RMSE'] - results['test_metrics']['RMSE']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test_R¬≤', ascending=False)\n",
    "\n",
    "print(\"=== COMPARACI√ìN DE MODELOS ===\")\n",
    "display(comparison_df.round(4))\n",
    "\n",
    "# Identificar el mejor modelo\n",
    "best_model_name = comparison_df.iloc[0]['Modelo']\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "print(f\"   Test R¬≤: {comparison_df.iloc[0]['Test_R¬≤']:.4f}\")\n",
    "print(f\"   Test RMSE: {comparison_df.iloc[0]['Test_RMSE']:.4f}\")\n",
    "print(f\"   CV RMSE: {comparison_df.iloc[0]['CV_RMSE']:.4f} (¬±{comparison_df.iloc[0]['CV_RMSE_Std']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de comparaci√≥n de modelos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# R¬≤ Score\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(comparison_df))\n",
    "ax1.bar(x_pos, comparison_df['Test_R¬≤'], alpha=0.7, color='lightblue')\n",
    "ax1.set_xlabel('Modelos')\n",
    "ax1.set_ylabel('R¬≤ Score')\n",
    "ax1.set_title('R¬≤ Score en Test Set')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(comparison_df['Modelo'], rotation=45)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE\n",
    "ax2 = axes[0, 1]\n",
    "ax2.bar(x_pos, comparison_df['Test_RMSE'], alpha=0.7, color='lightcoral')\n",
    "ax2.set_xlabel('Modelos')\n",
    "ax2.set_ylabel('RMSE')\n",
    "ax2.set_title('RMSE en Test Set')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(comparison_df['Modelo'], rotation=45)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Overfitting (Train RMSE - Test RMSE)\n",
    "ax3 = axes[1, 0]\n",
    "colors = ['red' if x > 0 else 'green' for x in comparison_df['Overfitting']]\n",
    "ax3.bar(x_pos, comparison_df['Overfitting'], alpha=0.7, color=colors)\n",
    "ax3.set_xlabel('Modelos')\n",
    "ax3.set_ylabel('Overfitting (Train RMSE - Test RMSE)')\n",
    "ax3.set_title('An√°lisis de Overfitting')\n",
    "ax3.set_xticks(x_pos)\n",
    "ax3.set_xticklabels(comparison_df['Modelo'], rotation=45)\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Cross-Validation RMSE con barras de error\n",
    "ax4 = axes[1, 1]\n",
    "ax4.bar(x_pos, comparison_df['CV_RMSE'], alpha=0.7, color='lightgreen',\n",
    "        yerr=comparison_df['CV_RMSE_Std'], capsize=5)\n",
    "ax4.set_xlabel('Modelos')\n",
    "ax4.set_ylabel('CV RMSE')\n",
    "ax4.set_title('Cross-Validation RMSE')\n",
    "ax4.set_xticks(x_pos)\n",
    "ax4.set_xticklabels(comparison_df['Modelo'], rotation=45)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. An√°lisis de Importancia de Caracter√≠sticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç ANALIZANDO IMPORTANCIA DE CARACTER√çSTICAS\")\n",
    "\n",
    "# Funci√≥n para obtener importancia de caracter√≠sticas\n",
    "def get_feature_importance(model, model_name, X_test, y_test):\n",
    "    \"\"\"Obtiene importancia de caracter√≠sticas seg√∫n el tipo de modelo\"\"\"\n",
    "    \n",
    "    if hasattr(model, 'feature_importances_'):\n",
    "        # Modelos con feature_importances_ (XGBoost, RandomForest, etc.)\n",
    "        importance = model.feature_importances_\n",
    "        method = 'Built-in Feature Importance'\n",
    "    \n",
    "    elif hasattr(model, 'coef_'):\n",
    "        # Modelos lineales\n",
    "        importance = np.abs(model.coef_)\n",
    "        method = 'Absolute Coefficients'\n",
    "    \n",
    "    else:\n",
    "        # Usar permutation importance para otros modelos\n",
    "        perm_importance = permutation_importance(\n",
    "            model, X_test, y_test, \n",
    "            n_repeats=10, random_state=42, \n",
    "            scoring='neg_mean_squared_error'\n",
    "        )\n",
    "        importance = perm_importance.importances_mean\n",
    "        method = 'Permutation Importance'\n",
    "    \n",
    "    return importance, method\n",
    "\n",
    "# Analizar importancia para los 3 mejores modelos\n",
    "top_3_models = comparison_df.head(3)\n",
    "importance_results = {}\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "for i, (_, row) in enumerate(top_3_models.iterrows()):\n",
    "    model_name = row['Modelo']\n",
    "    model_obj = all_results[model_name]['model']\n",
    "    \n",
    "    # Preparar datos de test seg√∫n el modelo\n",
    "    if model_name.startswith('SVR'):\n",
    "        X_test_prepared = robust_scaler.transform(X_test)\n",
    "    elif model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "        X_test_prepared = scaler.transform(X_test)\n",
    "    else:  # XGBoost\n",
    "        X_test_prepared = X_test\n",
    "    \n",
    "    importance, method = get_feature_importance(model_obj, model_name, X_test_prepared, y_test)\n",
    "    \n",
    "    # Normalizar importancia\n",
    "    importance_normalized = importance / importance.sum()\n",
    "    \n",
    "    # Crear DataFrame para visualizaci√≥n\n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_cols,\n",
    "        'Importance': importance_normalized\n",
    "    }).sort_values('Importance', ascending=True)\n",
    "    \n",
    "    importance_results[model_name] = importance_df\n",
    "    \n",
    "    # Gr√°fico\n",
    "    ax = axes[i]\n",
    "    colors = plt.cm.viridis(np.linspace(0, 1, len(importance_df)))\n",
    "    bars = ax.barh(importance_df['Feature'], importance_df['Importance'], color=colors)\n",
    "    ax.set_title(f'{model_name}\\n({method})')\n",
    "    ax.set_xlabel('Importancia Normalizada')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # A√±adir valores en las barras\n",
    "    for bar, importance in zip(bars, importance_df['Importance']):\n",
    "        ax.text(bar.get_width() + 0.005, bar.get_y() + bar.get_height()/2, \n",
    "                f'{importance:.3f}', ha='left', va='center', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Imprimir ranking de caracter√≠sticas\n",
    "print(\"\\n=== RANKING DE IMPORTANCIA DE CARACTER√çSTICAS ===\")\n",
    "for model_name, imp_df in importance_results.items():\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    for i, (_, row) in enumerate(imp_df.sort_values('Importance', ascending=False).iterrows(), 1):\n",
    "        print(f\"  {i}. {row['Feature']}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. An√°lisis de Residuos del Mejor Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionar el mejor modelo para an√°lisis detallado\n",
    "best_model_results = all_results[best_model_name]\n",
    "best_model = best_model_results['model']\n",
    "y_train_pred = best_model_results['predictions']['train']\n",
    "y_test_pred = best_model_results['predictions']['test']\n",
    "\n",
    "print(f\"üîç AN√ÅLISIS DE RESIDUOS - {best_model_name}\")\n",
    "\n",
    "# Calcular residuos\n",
    "train_residuals = y_train - y_train_pred\n",
    "test_residuals = y_test - y_test_pred\n",
    "\n",
    "# Crear gr√°ficos de an√°lisis de residuos\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# 1. Predicciones vs Valores Reales (Train)\n",
    "ax1 = axes[0, 0]\n",
    "ax1.scatter(y_train, y_train_pred, alpha=0.6, s=20)\n",
    "min_val = min(y_train.min(), y_train_pred.min())\n",
    "max_val = max(y_train.max(), y_train_pred.max())\n",
    "ax1.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "ax1.set_xlabel('Valores Reales')\n",
    "ax1.set_ylabel('Predicciones')\n",
    "ax1.set_title('Train: Predicciones vs Reales')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Predicciones vs Valores Reales (Test)\n",
    "ax2 = axes[0, 1]\n",
    "ax2.scatter(y_test, y_test_pred, alpha=0.6, s=20, color='orange')\n",
    "min_val = min(y_test.min(), y_test_pred.min())\n",
    "max_val = max(y_test.max(), y_test_pred.max())\n",
    "ax2.plot([min_val, max_val], [min_val, max_val], 'r--', linewidth=2)\n",
    "ax2.set_xlabel('Valores Reales')\n",
    "ax2.set_ylabel('Predicciones')\n",
    "ax2.set_title('Test: Predicciones vs Reales')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Residuos vs Predicciones (Test)\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(y_test_pred, test_residuals, alpha=0.6, s=20, color='green')\n",
    "ax3.axhline(y=0, color='r', linestyle='--')\n",
    "ax3.set_xlabel('Predicciones')\n",
    "ax3.set_ylabel('Residuos')\n",
    "ax3.set_title('Residuos vs Predicciones (Test)')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Histograma de Residuos (Train)\n",
    "ax4 = axes[1, 0]\n",
    "ax4.hist(train_residuals, bins=30, alpha=0.7, density=True, color='skyblue')\n",
    "ax4.axvline(train_residuals.mean(), color='red', linestyle='--', label=f'Media: {train_residuals.mean():.3f}')\n",
    "ax4.set_xlabel('Residuos')\n",
    "ax4.set_ylabel('Densidad')\n",
    "ax4.set_title('Distribuci√≥n de Residuos (Train)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Histograma de Residuos (Test)\n",
    "ax5 = axes[1, 1]\n",
    "ax5.hist(test_residuals, bins=30, alpha=0.7, density=True, color='orange')\n",
    "ax5.axvline(test_residuals.mean(), color='red', linestyle='--', label=f'Media: {test_residuals.mean():.3f}')\n",
    "ax5.set_xlabel('Residuos')\n",
    "ax5.set_ylabel('Densidad')\n",
    "ax5.set_title('Distribuci√≥n de Residuos (Test)')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Q-Q Plot de Residuos (Test)\n",
    "ax6 = axes[1, 2]\n",
    "stats.probplot(test_residuals, dist=\"norm\", plot=ax6)\n",
    "ax6.set_title('Q-Q Plot de Residuos (Test)')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Estad√≠sticas de residuos\n",
    "print(f\"\\n=== ESTAD√çSTICAS DE RESIDUOS ===\")\n",
    "print(f\"Train:\")\n",
    "print(f\"  Media: {train_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {train_residuals.std():.4f}\")\n",
    "print(f\"  Skewness: {stats.skew(train_residuals):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(train_residuals):.4f}\")\n",
    "\n",
    "print(f\"\\nTest:\")\n",
    "print(f\"  Media: {test_residuals.mean():.6f}\")\n",
    "print(f\"  Std: {test_residuals.std():.4f}\")\n",
    "print(f\"  Skewness: {stats.skew(test_residuals):.4f}\")\n",
    "print(f\"  Kurtosis: {stats.kurtosis(test_residuals):.4f}\")\n",
    "\n",
    "# Test de normalidad de residuos\n",
    "_, p_value = stats.shapiro(test_residuals[:1000] if len(test_residuals) > 1000 else test_residuals)\n",
    "print(f\"\\nTest de Normalidad (Shapiro-Wilk): p-value = {p_value:.6f}\")\n",
    "print(f\"Residuos son normales: {'S√≠' if p_value > 0.05 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Curvas de Aprendizaje y Validaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "print(f\"üîç GENERANDO CURVAS DE APRENDIZAJE PARA {best_model_name}\")\n",
    "\n",
    "# Preparar datos seg√∫n el mejor modelo\n",
    "if best_model_name.startswith('SVR'):\n",
    "    X_for_curves = robust_scaler.fit_transform(X_train)\n",
    "elif best_model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    X_for_curves = scaler.fit_transform(X_train)\n",
    "else:  # XGBoost\n",
    "    X_for_curves = X_train\n",
    "\n",
    "# Generar curvas de aprendizaje\n",
    "train_sizes, train_scores, val_scores = learning_curve(\n",
    "    best_model, X_for_curves, y_train,\n",
    "    cv=5, n_jobs=-1,\n",
    "    train_sizes=np.linspace(0.1, 1.0, 10),\n",
    "    scoring='neg_mean_squared_error'\n",
    ")\n",
    "\n",
    "# Convertir a RMSE\n",
    "train_rmse = np.sqrt(-train_scores)\n",
    "val_rmse = np.sqrt(-val_scores)\n",
    "\n",
    "# Calcular medias y desviaciones est√°ndar\n",
    "train_rmse_mean = train_rmse.mean(axis=1)\n",
    "train_rmse_std = train_rmse.std(axis=1)\n",
    "val_rmse_mean = val_rmse.mean(axis=1)\n",
    "val_rmse_std = val_rmse.std(axis=1)\n",
    "\n",
    "# Gr√°fico de curvas de aprendizaje\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train_sizes, train_rmse_mean, 'o-', color='blue', label='Training RMSE')\n",
    "plt.fill_between(train_sizes, train_rmse_mean - train_rmse_std, \n",
    "                 train_rmse_mean + train_rmse_std, alpha=0.1, color='blue')\n",
    "\n",
    "plt.plot(train_sizes, val_rmse_mean, 'o-', color='red', label='Validation RMSE')\n",
    "plt.fill_between(train_sizes, val_rmse_mean - val_rmse_std, \n",
    "                 val_rmse_mean + val_rmse_std, alpha=0.1, color='red')\n",
    "\n",
    "plt.xlabel('Tama√±o del conjunto de entrenamiento')\n",
    "plt.ylabel('RMSE')\n",
    "plt.title(f'Curvas de Aprendizaje - {best_model_name}')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# An√°lisis de las curvas\n",
    "final_gap = val_rmse_mean[-1] - train_rmse_mean[-1]\n",
    "print(f\"\\n=== AN√ÅLISIS DE CURVAS DE APRENDIZAJE ===\")\n",
    "print(f\"RMSE final en entrenamiento: {train_rmse_mean[-1]:.4f} (¬±{train_rmse_std[-1]:.4f})\")\n",
    "print(f\"RMSE final en validaci√≥n: {val_rmse_mean[-1]:.4f} (¬±{val_rmse_std[-1]:.4f})\")\n",
    "print(f\"Gap final (Val - Train): {final_gap:.4f}\")\n",
    "\n",
    "if final_gap > 0.1 * train_rmse_mean[-1]:\n",
    "    print(\"‚ö†Ô∏è Posible overfitting detectado\")\nelif final_gap < 0:\n",
    "    print(\"‚ö†Ô∏è Posible underfitting o datos de validaci√≥n m√°s f√°ciles\")\nelse:\n",
    "    print(\"‚úÖ Buen balance entre sesgo y varianza\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Optimizaci√≥n de Pesos para Maximizar Salida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize, differential_evolution\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "print(\"üéØ OPTIMIZACI√ìN DE PESOS PARA MAXIMIZAR SALIDA\")\n",
    "\n",
    "# Funci√≥n objetivo para maximizar la predicci√≥n\n",
    "def objective_function(weights, model, scaler=None, feature_names=None):\n",
    "    \"\"\"Funci√≥n objetivo: queremos maximizar la salida del modelo\"\"\"\n",
    "    weights_reshaped = weights.reshape(1, -1)\n",
    "    \n",
    "    # Aplicar escalado si es necesario\n",
    "    if scaler is not None:\n",
    "        weights_scaled = scaler.transform(weights_reshaped)\n",
    "    else:\n",
    "        weights_scaled = weights_reshaped\n",
    "    \n",
    "    # Predecir (queremos maximizar, as√≠ que retornamos el negativo)\n",
    "    prediction = model.predict(weights_scaled)[0]\n",
    "    return -prediction  # Negativo porque minimize busca el m√≠nimo\n",
    "\n",
    "# Definir l√≠mites para las caracter√≠sticas basados en los datos\n",
    "feature_bounds = []\n",
    "print(\"\\nL√≠mites de caracter√≠sticas basados en los datos:\")\n",
    "for i, feature in enumerate(feature_cols):\n",
    "    min_val = X[feature].min()\n",
    "    max_val = X[feature].max()\n",
    "    feature_bounds.append((min_val, max_val))\n",
    "    print(f\"  {feature}: [{min_val:.2f}, {max_val:.2f}]\")\n",
    "\n",
    "# Optimizar para el mejor modelo\n",
    "print(f\"\\nüîß Optimizando con {best_model_name}...\")\n",
    "\n",
    "# Preparar escalador si es necesario\n",
    "optimization_scaler = None\n",
    "if best_model_name.startswith('SVR'):\n",
    "    optimization_scaler = RobustScaler().fit(X_train)\nelif best_model_name in ['LinearRegression', 'Ridge', 'Lasso', 'ElasticNet']:\n",
    "    optimization_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "# Usar differential evolution (m√°s robusto para problemas no convexos)\n",
    "result = differential_evolution(\n",
    "    objective_function,\n",
    "    feature_bounds,\n",
    "    args=(best_model, optimization_scaler, feature_cols),\n",
    "    seed=42,\n",
    "    maxiter=1000,\n",
    "    popsize=15\n",
    ")\n",
    "\n",
    "optimal_weights = result.x\n",
    "optimal_prediction = -result.fun  # Convertir de vuelta (quitamos el negativo)\n",
    "\n",
    "print(f\"\\n‚úÖ OPTIMIZACI√ìN COMPLETADA\")\n",
    "print(f\"Valor m√°ximo predicho: {optimal_prediction:.4f}\")\n",
    "print(f\"N√∫mero de evaluaciones: {result.nfev}\")\n",
    "print(f\"√âxito: {result.success}\")\n",
    "\n",
    "# Mostrar pesos √≥ptimos\n",
    "print(f\"\\n=== PESOS √ìPTIMOS PARA MAXIMIZAR SALIDA ===\")\n",
    "optimal_df = pd.DataFrame({\n",
    "    'Caracter√≠stica': feature_cols,\n",
    "    'Valor_√ìptimo': optimal_weights,\n",
    "    'Min_Datos': [X[col].min() for col in feature_cols],\n",
    "    'Max_Datos': [X[col].max() for col in feature_cols],\n",
    "    'Percentil_en_Datos': [stats.percentileofscore(X[col], val) for col, val in zip(feature_cols, optimal_weights)]\n",
    "})\n",
    "\n",
    "display(optimal_df.round(4))\n",
    "\n",
    "# Comparar con algunos ejemplos del dataset\n",
    "print(f\"\\n=== COMPARACI√ìN CON DATOS EXISTENTES ===\")\n",
    "# Encontrar las 5 muestras con mayor valor de target\n",
    "top_5_indices = y.nlargest(5).index\n",
    "top_5_predictions = []\n",
    "\n",
    "for idx in top_5_indices:\n",
    "    sample = X.loc[idx].values.reshape(1, -1)\n",
    "    if optimization_scaler is not None:\n",
    "        sample_scaled = optimization_scaler.transform(sample)\n",
    "    else:\n",
    "        sample_scaled = sample\n",
    "    pred = best_model.predict(sample_scaled)[0]\n",
    "    top_5_predictions.append(pred)\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Tipo': ['Top 1 del dataset', 'Top 2 del dataset', 'Top 3 del dataset', 'Top 4 del dataset', 'Top 5 del dataset', 'PESOS √ìPTIMOS'],\n",
    "    'Predicci√≥n': top_5_predictions + [optimal_prediction],\n",
    "    'Target_Real': list(y.loc[top_5_indices]) + ['N/A']\n",
    "})\n",
    "\n",
    "display(comparison_df.round(4))\n",
    "\n",
    "improvement = optimal_prediction - max(top_5_predictions)\n",
    "print(f\"\\nMejora sobre el mejor caso del dataset: {improvement:.4f} ({improvement/max(top_5_predictions)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Visualizaci√≥n de Pesos √ìptimos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizaci√≥n de pesos √≥ptimos\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Valores √≥ptimos vs rangos de datos\n",
    "ax1 = axes[0, 0]\n",
    "x_pos = np.arange(len(feature_cols))\n",
    "ax1.bar(x_pos, optimal_weights, alpha=0.7, color='gold', label='Valores √ìptimos')\n",
    "\n",
    "# Agregar l√≠neas para min/max de datos\n",
    "mins = [X[col].min() for col in feature_cols]\n",
    "maxs = [X[col].max() for col in feature_cols]\n",
    "ax1.errorbar(x_pos, optimal_weights, \n",
    "            yerr=[np.array(optimal_weights) - np.array(mins), \n",
    "                  np.array(maxs) - np.array(optimal_weights)], \n",
    "            fmt='none', color='red', alpha=0.5, capsize=5)\n",
    "\n",
    "ax1.set_xlabel('Caracter√≠sticas')\n",
    "ax1.set_ylabel('Valores')\n",
    "ax1.set_title('Valores √ìptimos vs Rangos de Datos')\n",
    "ax1.set_xticks(x_pos)\n",
    "ax1.set_xticklabels(feature_cols, rotation=45)\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Percentiles de los valores √≥ptimos\n",
    "ax2 = axes[0, 1]\n",
    "percentiles = optimal_df['Percentil_en_Datos']\n",
    "colors = ['red' if p > 90 else 'orange' if p > 75 else 'yellow' if p > 50 else 'lightblue' for p in percentiles]\n",
    "bars = ax2.bar(x_pos, percentiles, color=colors, alpha=0.7)\n",
    "ax2.axhline(y=50, color='gray', linestyle='--', alpha=0.7, label='Mediana')\n",
    "ax2.axhline(y=90, color='red', linestyle='--', alpha=0.7, label='Percentil 90')\n",
    "ax2.set_xlabel('Caracter√≠sticas')\n",
    "ax2.set_ylabel('Percentil')\n",
    "ax2.set_title('Percentiles de Valores √ìptimos')\n",
    "ax2.set_xticks(x_pos)\n",
    "ax2.set_xticklabels(feature_cols, rotation=45)\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar etiquetas con percentiles\n",
    "for bar, p in zip(bars, percentiles):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1, \n",
    "            f'{p:.0f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 3. Comparaci√≥n con mejores muestras del dataset\n",
    "ax3 = axes[1, 0]\n",
    "comparison_values = list(comparison_df['Predicci√≥n'][:-1]) + [optimal_prediction]\n",
    "labels = ['Top 1', 'Top 2', 'Top 3', 'Top 4', 'Top 5', '√ìptimo']\n",
    "colors = ['lightblue'] * 5 + ['gold']\n",
    "\n",
    "bars = ax3.bar(labels, comparison_values, color=colors, alpha=0.7)\n",
    "ax3.set_xlabel('Muestras')\n",
    "ax3.set_ylabel('Predicci√≥n')\n",
    "ax3.set_title('Comparaci√≥n: Mejores Muestras vs √ìptimo')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Agregar etiquetas con valores\n",
    "for bar, val in zip(bars, comparison_values):\n",
    "    ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + max(comparison_values)*0.01, \n",
    "            f'{val:.2f}', ha='center', va='bottom', fontsize=9)\n",
    "\n",
    "# 4. Radar chart comparando √≥ptimo vs promedio del dataset\n",
    "ax4 = axes[1, 1]\n",
    "angles = np.linspace(0, 2*np.pi, len(feature_cols), endpoint=False).tolist()\n",
    "angles += angles[:1]  # Completar el c√≠rculo\n",
    "\n",
    "# Normalizar valores para el radar chart\n",
    "scaler_radar = MinMaxScaler()\n",
    "data_for_radar = np.column_stack([optimal_weights, X[feature_cols].mean().values])\n",
    "normalized_data = scaler_radar.fit_transform(data_for_radar)\n",
    "\n",
    "optimal_normalized = normalized_data[:, 0].tolist()\n",
    "mean_normalized = normalized_data[:, 1].tolist()\n",
    "\n",
    "optimal_normalized += optimal_normalized[:1]\n",
    "mean_normalized += mean_normalized[:1]\n",
    "\n",
    "ax4 = plt.subplot(2, 2, 4, projection='polar')\n",
    "ax4.plot(angles, optimal_normalized, 'o-', linewidth=2, label='Valores √ìptimos', color='gold')\n",
    "ax4.fill(angles, optimal_normalized, alpha=0.25, color='gold')\n",
    "ax4.plot(angles, mean_normalized, 'o-', linewidth=2, label='Promedio Dataset', color='blue')\n",
    "ax4.fill(angles, mean_normalized, alpha=0.25, color='blue')\n",
    "\n",
    "ax4.set_xticks(angles[:-1])\n",
    "ax4.set_xticklabels(feature_cols)\n",
    "ax4.set_ylim(0, 1)\n",
    "ax4.set_title('Comparaci√≥n Radar: √ìptimo vs Promedio', y=1.08)\n",
    "ax4.legend(loc='upper right', bbox_to_anchor=(1.2, 1.0))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Resumen Final y Recomendaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"üéØ RESUMEN FINAL DEL PROYECTO DE MACHINE LEARNING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä DATASET:\")\n",
    "print(f\"   ‚Ä¢ Tama√±o: {X.shape[0]} muestras, {X.shape[1]} caracter√≠sticas\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas: {', '.join(feature_cols)}\")\n",
    "print(f\"   ‚Ä¢ Split: {X_train.shape[0]} train / {X_test.shape[0]} test\")\n",
    "\n",
    "print(f\"\\nü§ñ MODELOS EVALUADOS:\")\n",
    "models_tested = len(all_results)\n",
    "print(f\"   ‚Ä¢ Total de modelos: {models_tested}\")\n",
    "print(f\"   ‚Ä¢ Regresi√≥n Lineal: {len(linear_results)} variantes\")\n",
    "print(f\"   ‚Ä¢ Support Vector Regression: {len(svr_results)} kernels\")\n",
    "print(f\"   ‚Ä¢ XGBoost: 1 modelo con hiperpar√°metros optimizados\")\n",
    "\n",
    "print(f\"\\nüèÜ MEJOR MODELO: {best_model_name}\")\n",
    "best_test_metrics = best_model_results['test_metrics']\n",
    "print(f\"   ‚Ä¢ R¬≤ Score: {best_test_metrics['R¬≤']:.4f}\")\n",
    "print(f\"   ‚Ä¢ RMSE: {best_test_metrics['RMSE']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAE: {best_test_metrics['MAE']:.4f}\")\n",
    "print(f\"   ‚Ä¢ MAPE: {best_test_metrics['MAPE']:.2f}%\")\n",
    "print(f\"   ‚Ä¢ CV RMSE: {best_model_results['cv_rmse']:.4f} (¬±{best_model_results['cv_rmse_std']:.4f})\")\n",
    "\n",
    "print(f\"\\nüéØ CARACTER√çSTICAS M√ÅS IMPORTANTES:\")\n",
    "if best_model_name in importance_results:\n",
    "    top_features = importance_results[best_model_name].sort_values('Importance', ascending=False).head(3)\n",
    "    for i, (_, row) in enumerate(top_features.iterrows(), 1):\n",
    "        print(f\"   {i}. {row['Feature']}: {row['Importance']:.4f}\")\n",
    "\n",
    "print(f\"\\n‚ö° PESOS √ìPTIMOS PARA MAXIMIZACI√ìN:\")\n",
    "print(f\"   ‚Ä¢ Valor m√°ximo predicho: {optimal_prediction:.4f}\")\n",
    "print(f\"   ‚Ä¢ Mejora sobre mejor muestra: {improvement:.4f} ({improvement/max(top_5_predictions)*100:.2f}%)\")\n",
    "print(f\"   ‚Ä¢ Caracter√≠sticas que deben maximizarse:\")\n",
    "high_percentile_features = optimal_df[optimal_df['Percentil_en_Datos'] > 75]\n",
    "for _, row in high_percentile_features.iterrows():\n",
    "    print(f\"     - {row['Caracter√≠stica']}: {row['Valor_√ìptimo']:.2f} (percentil {row['Percentil_en_Datos']:.0f})\")\n",
    "\n",
    "print(f\"\\nüìà AN√ÅLISIS DE CALIDAD DEL MODELO:\")\n",
    "overfitting_score = best_model_results['train_metrics']['RMSE'] - best_model_results['test_metrics']['RMSE']\n",
    "if abs(overfitting_score) < 0.1 * best_model_results['test_metrics']['RMSE']:\n",
    "    print(f\"   ‚Ä¢ ‚úÖ Buen balance entre sesgo y varianza\")\nelif overfitting_score > 0:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è Ligero overfitting detectado (diferencia: {overfitting_score:.4f})\")\nelse:\n",
    "    print(f\"   ‚Ä¢ ‚ö†Ô∏è Posible underfitting\")\n",
    "\n",
    "if best_test_metrics['R¬≤'] > 0.8:\n",
    "    quality = \"Excelente\"\nelif best_test_metrics['R¬≤'] > 0.6:\n",
    "    quality = \"Bueno\"\nelif best_test_metrics['R¬≤'] > 0.4:\n",
    "    quality = \"Regular\"\nelse:\n",
    "    quality = \"Necesita mejora\"\n",
    "    \n",
    "print(f\"   ‚Ä¢ Calidad del ajuste: {quality} (R¬≤ = {best_test_metrics['R¬≤']:.4f})\")\n",
    "\n",
    "print(f\"\\nüî¨ RECOMENDACIONES:\")\n",
    "print(f\"   ‚Ä¢ Para maximizar la salida, use los pesos √≥ptimos encontrados\")\n",
    "print(f\"   ‚Ä¢ Foque en las caracter√≠sticas de mayor importancia identificadas\")\n",
    "\n",
    "if best_test_metrics['R¬≤'] < 0.8:\n",
    "    print(f\"   ‚Ä¢ Considere feature engineering adicional para mejorar el R¬≤\")\n",
    "    print(f\"   ‚Ä¢ Explore modelos m√°s complejos (Neural Networks, Ensemble methods)\")\n",
    "    \n",
    "if abs(overfitting_score) > 0.1 * best_model_results['test_metrics']['RMSE']:\n",
    "    print(f\"   ‚Ä¢ Considere t√©cnicas de regularizaci√≥n adicionales\")\n",
    "    print(f\"   ‚Ä¢ Aumente el tama√±o del dataset de entrenamiento si es posible\")\n",
    "\n",
    "print(f\"   ‚Ä¢ Use validaci√≥n cruzada para decisiones de producci√≥n\")\n",
    "print(f\"   ‚Ä¢ Monitoree el rendimiento del modelo en datos nuevos\")\n",
    "\n",
    "print(f\"\\nüíæ ARCHIVOS GENERADOS:\")\n",
    "print(f\"   ‚Ä¢ 01_exploratory_data_analysis.ipynb: An√°lisis exploratorio completo\")\n",
    "print(f\"   ‚Ä¢ 02_model_training_evaluation.ipynb: Entrenamiento y evaluaci√≥n de modelos\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"‚ú® PROYECTO COMPLETADO EXITOSAMENTE ‚ú®\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}